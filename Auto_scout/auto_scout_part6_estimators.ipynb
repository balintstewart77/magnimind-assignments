{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "# For data splitting\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# For scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For modeling\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# For pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import additional estimators\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/auto_scout_final.csv')\n",
    "# Create features and targey variable\n",
    "X = df.drop('price', axis = 1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaler\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_scaled = standard_scaler.fit_transform(X_train) # train the scalar on the train dataset\n",
    "X_test_scaled = standard_scaler.transform(X_test) # transform test datasets, make sure you don't fit to test data though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and initial pass of all the major types of estimators (not fine-tuned) on the data and compare performance on train and test datasets. Try unscaled data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dict to store evaluation results\n",
    "results = {}\n",
    "\n",
    "models = {'SVR': SVR(),\n",
    "          'Random Forest': RandomForestRegressor(),\n",
    "          'Gradient Boost': GradientBoostingRegressor(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'XG Boost': XGBRegressor()}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    #unscaled data\n",
    "    model.fit(X_train, y_train)\n",
    "    # make predictions on the training data and the test data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    # Gather evaluation metrics mean_squared_error and r2_score on both train and test datasets\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    train_MSE = mean_squared_error(y_train, y_train_pred)\n",
    "    test_MSE = mean_squared_error(y_test, y_test_pred)\n",
    "    train_RMSE = np.sqrt(train_MSE)\n",
    "    test_RMSE = np.sqrt(test_MSE)\n",
    "    # put these results into my results dict\n",
    "    results[model_name] = {\n",
    "        'Train R^2':train_r2,\n",
    "        'Test R^2':test_r2,\n",
    "        'Train RMSE':train_RMSE,\n",
    "        'Test RMSE': test_RMSE\n",
    "    }\n",
    "\n",
    "# convert dict into df\n",
    "results_unscaled = pd.DataFrame(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train R^2</th>\n",
       "      <th>Test R^2</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.055281</td>\n",
       "      <td>0.062925</td>\n",
       "      <td>7252.321013</td>\n",
       "      <td>6904.640536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.993582</td>\n",
       "      <td>0.953082</td>\n",
       "      <td>597.771658</td>\n",
       "      <td>1544.986808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.929669</td>\n",
       "      <td>1803.667987</td>\n",
       "      <td>1891.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression</th>\n",
       "      <td>0.899707</td>\n",
       "      <td>0.890865</td>\n",
       "      <td>2362.981372</td>\n",
       "      <td>2356.329187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG Boost</th>\n",
       "      <td>0.987915</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>820.251350</td>\n",
       "      <td>1482.156908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train R^2  Test R^2   Train RMSE    Test RMSE\n",
       "SVR                0.055281  0.062925  7252.321013  6904.640536\n",
       "Random Forest      0.993582  0.953082   597.771658  1544.986808\n",
       "Gradient Boost     0.941567  0.929669  1803.667987  1891.592593\n",
       "Lasso Regression   0.899707  0.890865  2362.981372  2356.329187\n",
       "XG Boost           0.987915  0.956820   820.251350  1482.156908"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_unscaled.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare performance on the scaled data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dict to store evaluation results\n",
    "results = {}\n",
    "\n",
    "models = {'SVR': SVR(),\n",
    "          'Random Forest': RandomForestRegressor(),\n",
    "          'Gradient Boost': GradientBoostingRegressor(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'XG Boost': XGBRegressor()}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    #unscaled data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    # make predictions on the training data and the test data\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    # Gather evaluation metrics mean_squared_error and r2_score on both train and test datasets\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    train_MSE = mean_squared_error(y_train, y_train_pred)\n",
    "    test_MSE = mean_squared_error(y_test, y_test_pred)\n",
    "    train_RMSE = np.sqrt(train_MSE)\n",
    "    test_RMSE = np.sqrt(test_MSE)\n",
    "    # put these results into my results dict\n",
    "    results[model_name] = {\n",
    "        'Train R^2 scaled':train_r2,\n",
    "        'Test R^2 scaled':test_r2,\n",
    "        'Train RMSE scaled':train_RMSE,\n",
    "        'Test RMSE scaled': test_RMSE\n",
    "    }\n",
    "\n",
    "# convert dict into df\n",
    "results_scaled = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gradient Boost</th>\n",
       "      <th>Lasso Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVR</th>\n",
       "      <th>XG Boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train R^2</th>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.899707</td>\n",
       "      <td>0.993582</td>\n",
       "      <td>0.055281</td>\n",
       "      <td>0.987915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test R^2</th>\n",
       "      <td>0.929669</td>\n",
       "      <td>0.890865</td>\n",
       "      <td>0.953082</td>\n",
       "      <td>0.062925</td>\n",
       "      <td>0.956820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train RMSE</th>\n",
       "      <td>1803.667987</td>\n",
       "      <td>2362.981372</td>\n",
       "      <td>597.771658</td>\n",
       "      <td>7252.321013</td>\n",
       "      <td>820.251350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test RMSE</th>\n",
       "      <td>1891.592593</td>\n",
       "      <td>2356.329187</td>\n",
       "      <td>1544.986808</td>\n",
       "      <td>6904.640536</td>\n",
       "      <td>1482.156908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train R^2 scaled</th>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.900008</td>\n",
       "      <td>0.993484</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>0.987915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test R^2 scaled</th>\n",
       "      <td>0.929787</td>\n",
       "      <td>0.890716</td>\n",
       "      <td>0.951829</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.956820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train RMSE scaled</th>\n",
       "      <td>1803.667987</td>\n",
       "      <td>2359.439317</td>\n",
       "      <td>602.305156</td>\n",
       "      <td>7428.918463</td>\n",
       "      <td>820.251350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test RMSE scaled</th>\n",
       "      <td>1890.003148</td>\n",
       "      <td>2357.932108</td>\n",
       "      <td>1565.469634</td>\n",
       "      <td>7073.205589</td>\n",
       "      <td>1482.156908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Gradient Boost  Lasso Regression  Random Forest  \\\n",
       "Train R^2                0.941567          0.899707       0.993582   \n",
       "Test R^2                 0.929669          0.890865       0.953082   \n",
       "Train RMSE            1803.667987       2362.981372     597.771658   \n",
       "Test RMSE             1891.592593       2356.329187    1544.986808   \n",
       "Train R^2 scaled         0.941567          0.900008       0.993484   \n",
       "Test R^2 scaled          0.929787          0.890716       0.951829   \n",
       "Train RMSE scaled     1803.667987       2359.439317     602.305156   \n",
       "Test RMSE scaled      1890.003148       2357.932108    1565.469634   \n",
       "\n",
       "                           SVR     XG Boost  \n",
       "Train R^2             0.055281     0.987915  \n",
       "Test R^2              0.062925     0.956820  \n",
       "Train RMSE         7252.321013   820.251350  \n",
       "Test RMSE          6904.640536  1482.156908  \n",
       "Train R^2 scaled      0.008712     0.987915  \n",
       "Test R^2 scaled       0.016612     0.956820  \n",
       "Train RMSE scaled  7428.918463   820.251350  \n",
       "Test RMSE scaled   7073.205589  1482.156908  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([results_unscaled, results_scaled], axis = 0)\n",
    "results[sorted(results)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data doesn't seem to affect performance across these models. XG Boost is best performing model, test RMSE = 1482, R^2 = 0.957"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log transforming the target variable improved linear regression a bit, can it improve the other models too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation to the target variable\n",
    "y_train_log = np.log(y_train)\n",
    "y_test_log = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dict to store evaluation results\n",
    "results = {}\n",
    "\n",
    "models = {'SVR': SVR(),\n",
    "          'Random Forest': RandomForestRegressor(),\n",
    "          'Gradient Boost': GradientBoostingRegressor(),\n",
    "          'Lasso Regression': Lasso(),\n",
    "          'XG Boost': XGBRegressor()}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    #unscaled data\n",
    "    model.fit(X_train, y_train_log)\n",
    "    # make predictions on the training data and the test data\n",
    "    y_train_pred_log = model.predict(X_train)\n",
    "    y_test_pred_log = model.predict(X_test)\n",
    "    # Inverse log transform the predictions and the true values to original scale, so can compare RMSE values across log and non-transformed target variable\n",
    "    y_train_pred_original = np.exp(y_train_pred_log)\n",
    "    y_test_pred_original = np.exp(y_test_pred_log)\n",
    "    y_train_original = np.exp(y_train_log)\n",
    "    y_test_original = np.exp(y_test_log)\n",
    "    # Gather evaluation metrics mean_squared_error and r2_score on both train and test datasets\n",
    "    train_r2 = r2_score(y_train_log, y_train_pred_log)\n",
    "    test_r2 = r2_score(y_test_log, y_test_pred_log)\n",
    "    train_MSE = mean_squared_error(y_train_original, y_train_pred_original)\n",
    "    test_MSE = mean_squared_error(y_test_original, y_test_pred_original)\n",
    "    train_RMSE = np.sqrt(train_MSE)\n",
    "    test_RMSE = np.sqrt(test_MSE)\n",
    "    # put these results into my results dict\n",
    "    results[model_name] = {\n",
    "        'Train R^2 log':train_r2,\n",
    "        'Test R^2 log':test_r2,\n",
    "        'Train RMSE log':train_RMSE,\n",
    "        'Test RMSE log': test_RMSE\n",
    "    }\n",
    "\n",
    "# convert dict into df\n",
    "results_logTarget = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVR</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boost</th>\n",
       "      <th>Lasso Regression</th>\n",
       "      <th>XG Boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train R^2 log</th>\n",
       "      <td>0.418725</td>\n",
       "      <td>0.994984</td>\n",
       "      <td>0.949012</td>\n",
       "      <td>0.637676</td>\n",
       "      <td>0.988452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test R^2 log</th>\n",
       "      <td>0.401748</td>\n",
       "      <td>0.964122</td>\n",
       "      <td>0.940318</td>\n",
       "      <td>0.628680</td>\n",
       "      <td>0.964064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train RMSE log</th>\n",
       "      <td>5481.985217</td>\n",
       "      <td>619.653999</td>\n",
       "      <td>1909.857965</td>\n",
       "      <td>4444.689957</td>\n",
       "      <td>852.900651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test RMSE log</th>\n",
       "      <td>5306.539663</td>\n",
       "      <td>1489.743771</td>\n",
       "      <td>2006.577713</td>\n",
       "      <td>4245.152026</td>\n",
       "      <td>1466.117084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        SVR  Random Forest  Gradient Boost  Lasso Regression  \\\n",
       "Train R^2 log      0.418725       0.994984        0.949012          0.637676   \n",
       "Test R^2 log       0.401748       0.964122        0.940318          0.628680   \n",
       "Train RMSE log  5481.985217     619.653999     1909.857965       4444.689957   \n",
       "Test RMSE log   5306.539663    1489.743771     2006.577713       4245.152026   \n",
       "\n",
       "                   XG Boost  \n",
       "Train R^2 log      0.988452  \n",
       "Test R^2 log       0.964064  \n",
       "Train RMSE log   852.900651  \n",
       "Test RMSE log   1466.117084  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_logTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performance so far for Random Forest and XGBoost: XG Boost has R^2 = 0.964 RMSE = 1466, RF R^2 = 0.963 and RMSE = 1515\n",
    "\n",
    "Compare training speed for RF and XG Boost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare training speed for XGBoost and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training time: 13.7784 seconds\n",
      "XGBoost training time: 0.2274 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "rf =  RandomForestRegressor()\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Measure time for Random Forest training\n",
    "start_time_rf = time.time()\n",
    "rf.fit(X_train, y_train_log)\n",
    "end_time_rf = time.time()\n",
    "rf_training_time = end_time_rf - start_time_rf\n",
    "\n",
    "# Measure time for XGBoost training\n",
    "start_time_xgb = time.time()\n",
    "xgb.fit(X_train, y_train_log)\n",
    "end_time_xgb = time.time()\n",
    "xgb_training_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "# Print the training times\n",
    "print(f\"Random Forest training time: {rf_training_time:.4f} seconds\")\n",
    "print(f\"XGBoost training time: {xgb_training_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both quite fast? XGBoost slightly better performing and quicker to train (even though trees are trained sequencially rather than in parallel, shouldn't this make it slower to train than RF?), try to tune XGBoost to see if I can get even better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost has lots of params to tune! Can still do gridsearch across these as training time only 0.2 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2187 candidates, totalling 6561 fits\n",
      "Best Parameters: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 500, 'subsample': 0.8}\n",
      "Best Score (RMSE): nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BalintStewart\\AppData\\Local\\Temp\\ipykernel_3664\\1635456543.py:18: RuntimeWarning: invalid value encountered in sqrt\n",
      "  best_score_RMSE = np.sqrt(-best_score_MSE)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 500],        # no of boosting rounds (trees), generally 500 upper limit? can get overfitting with more trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1],     \n",
    "    'max_depth': [5, 7, 10],                 # this dataset quite big so deeper tree better?\n",
    "    'subsample': [0.7, 0.8, 1.0],           # fraction of samples used to grow each tree. values between 0.7 and 1 commonly tested\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],    # fraction of features used to grow each tree \n",
    "    'gamma': [0, 0.1, 0.2],                 # min loss reduction required to make a split\n",
    "    'min_child_weight': [1, 2, 3],          # min number of samples needed in each leaf\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = xgb, param_grid= param_grid,\n",
    "                           cv = 3, verbose = 1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train_log)\n",
    "# Get the best parameters and model performance\n",
    "best_params = grid_search.best_params_\n",
    "best_score_MSE = grid_search.best_score_ #this is neg value\n",
    "best_score_RMSE = np.sqrt(-best_score_MSE)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score (RMSE): {best_score_RMSE:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 500, 'subsample': 0.8}\n",
      "Best Score (RMSE): 0.9836\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters and model performance\n",
    "best_params = grid_search.best_params_\n",
    "best_score_MSE = grid_search.best_score_ #this is neg value\n",
    "best_score_MSE = abs(grid_search.best_score_)\n",
    "best_score_RMSE = np.sqrt(best_score_MSE)\n",
    "                  \n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score (RMSE): {best_score_RMSE:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth = 7 was the deepest option in the grid, dataset is quite large so could mean we could improve by increasing this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(colsample_bytree = 0.7, gamma = 0, learning_rate = 0.05, max_depth = 7, min_child_weight = 2, n_estimators = 500, subsample = 0.8)\n",
    "\n",
    "model.fit(X_train, y_train_log)\n",
    "# make predictions on the training data and the test data\n",
    "y_train_pred_log = model.predict(X_train)\n",
    "y_test_pred_log = model.predict(X_test)\n",
    "# Inverse log transform the predictions and the true values to original scale, so can compare RMSE values across log and non-transformed target variable\n",
    "y_train_pred_original = np.exp(y_train_pred_log)\n",
    "y_test_pred_original = np.exp(y_test_pred_log)\n",
    "y_train_original = np.exp(y_train_log)\n",
    "y_test_original = np.exp(y_test_log)\n",
    "# Gather evaluation metrics mean_squared_error and r2_score on both train and test datasets\n",
    "train_r2 = r2_score(y_train_log, y_train_pred_log)\n",
    "test_r2 = r2_score(y_test_log, y_test_pred_log)\n",
    "train_MSE = mean_squared_error(y_train_original, y_train_pred_original)\n",
    "test_MSE = mean_squared_error(y_test_original, y_test_pred_original)\n",
    "train_RMSE = np.sqrt(train_MSE)\n",
    "test_RMSE = np.sqrt(test_MSE)\n",
    "\n",
    "results = {\n",
    "        'Train R^2':train_r2,\n",
    "        'Test R^2':test_r2,\n",
    "        'Train RMSE':train_RMSE,\n",
    "        'Test RMSE': test_RMSE\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train R^2</th>\n",
       "      <th>Test R^2</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.992886</td>\n",
       "      <td>0.969465</td>\n",
       "      <td>659.362743</td>\n",
       "      <td>1384.558161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train R^2  Test R^2  Train RMSE    Test RMSE\n",
       "XGBoost   0.992886  0.969465  659.362743  1384.558161"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_tuned = pd.DataFrame(results, index=['XGBoost'])\n",
    "XGB_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is very good but model is still overfitting a little bit. Could decrease learning rate, and/or increase min_child_rate, gains likely to be quite small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result I can find using XGBoost is R^2 0.969, RMSE = $1385"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
